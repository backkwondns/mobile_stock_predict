{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fb5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6e66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size=5):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i:i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ae3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data_dir/train_KOSPI_0616.csv\")\n",
    "df[\"Medium\"] = df[[\"High\", \"Low\"]].mean(axis = 1)\n",
    "feature_Df = df[[\"High\", \"Low\", \"Open\", \"Medium\"]]\n",
    "target_Df = df[\"Close\"]\n",
    "train_Feature, train_Label = make_dataset(feature_Df, target_Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce3cafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 425\n",
      "Trainable params: 425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature = 4\n",
    "timesteps = 5\n",
    "cell_size = 8\n",
    "#learning_rate = 0.1\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "input_shape = (timesteps, feature)\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(cell_size, input_shape = input_shape,activation=\"relu\", return_sequences = False))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.LSTM(cell_size))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1))\n",
    "optimizer = K.optimizers.Adam() #(lr = learning_rate)\n",
    "loss_func = K.losses.mse\n",
    "acc = K.metrics.RootMeanSquaredError\n",
    "model.compile(optimizer = optimizer, loss = loss_func, metrics = [K.metrics.RootMeanSquaredError()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0122ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "374/374 [==============================] - 28s 55ms/step - loss: 1082263.6347 - root_mean_squared_error: 1034.6937\n",
      "Epoch 2/30\n",
      "374/374 [==============================] - 20s 55ms/step - loss: 217922.2904 - root_mean_squared_error: 461.5734\n",
      "Epoch 3/30\n",
      "374/374 [==============================] - 20s 54ms/step - loss: 8327.7070 - root_mean_squared_error: 88.7090 1s - loss: 8597.2610 - root_mean_squared_err - ETA: 0s - loss: 8419.2953 - root_mean_squared_error: 8\n",
      "Epoch 4/30\n",
      "374/374 [==============================] - 25s 68ms/step - loss: 741.6642 - root_mean_squared_error: 27.04871s - loss: 745.4351 \n",
      "Epoch 5/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 617.1027 - root_mean_squared_error: 24.7511\n",
      "Epoch 6/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 500.9249 - root_mean_squared_error: 22.2949\n",
      "Epoch 7/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 653.9618 - root_mean_squared_error: 25.3229\n",
      "Epoch 8/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 505.1883 - root_mean_squared_error: 22.3784\n",
      "Epoch 9/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 518.1114 - root_mean_squared_error: 22.6778\n",
      "Epoch 10/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 558.1321 - root_mean_squared_error: 23.5133\n",
      "Epoch 11/30\n",
      "374/374 [==============================] - 26s 71ms/step - loss: 514.5345 - root_mean_squared_error: 22.6231\n",
      "Epoch 12/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 458.8509 - root_mean_squared_error: 21.3709\n",
      "Epoch 13/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 517.3312 - root_mean_squared_error: 22.6759\n",
      "Epoch 14/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 435.8931 - root_mean_squared_error: 20.8462\n",
      "Epoch 15/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 446.3549 - root_mean_squared_error: 21.07361s - loss: 4\n",
      "Epoch 16/30\n",
      "374/374 [==============================] - 26s 68ms/step - loss: 1108.4828 - root_mean_squared_error: 31.1345\n",
      "Epoch 17/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 574.1808 - root_mean_squared_error: 23.82045s - loss: 554.0971  - E\n",
      "Epoch 18/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 763.1462 - root_mean_squared_error: 27.4239\n",
      "Epoch 19/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 495.6558 - root_mean_squared_error: 22.2147\n",
      "Epoch 20/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 734.4895 - root_mean_squared_error: 26.83271s - loss: 739.736\n",
      "Epoch 21/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 693.8135 - root_mean_squared_error: 26.2125\n",
      "Epoch 22/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 506.5108 - root_mean_squared_error: 22.4833\n",
      "Epoch 23/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 533.7235 - root_mean_squared_error: 22.9168\n",
      "Epoch 24/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 477.7074 - root_mean_squared_error: 21.8137\n",
      "Epoch 25/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 699.6582 - root_mean_squared_error: 26.3042\n",
      "Epoch 26/30\n",
      "374/374 [==============================] - 26s 70ms/step - loss: 590.1242 - root_mean_squared_error: 24.1164\n",
      "Epoch 27/30\n",
      "374/374 [==============================] - 22s 59ms/step - loss: 516.2056 - root_mean_squared_error: 22.6346\n",
      "Epoch 28/30\n",
      "374/374 [==============================] - 20s 54ms/step - loss: 570.7569 - root_mean_squared_error: 23.7653\n",
      "Epoch 29/30\n",
      "374/374 [==============================] - 24s 64ms/step - loss: 736.0954 - root_mean_squared_error: 26.9074\n",
      "Epoch 30/30\n",
      "374/374 [==============================] - 26s 69ms/step - loss: 817.3055 - root_mean_squared_error: 28.19150s - loss: 817.8701 - root_mean_squared_error: 28.20\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_Feature, train_Label, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4270e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./test_KOSPI_0616.csv\")\n",
    "test_df[\"Medium\"] = test_df[[\"High\", \"Low\"]].mean(axis = 1)\n",
    "feature_test = test_df[[\"High\", \"Low\", \"Open\", \"Medium\"]]\n",
    "target_test = test_df[\"Close\"]\n",
    "test_Feature, test_Label = make_dataset(feature_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68b84730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e881008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b055913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3131.3115],\n",
       "       [3137.116 ],\n",
       "       [3140.597 ],\n",
       "       [3143.688 ],\n",
       "       [3152.3389],\n",
       "       [3166.2812],\n",
       "       [3182.2385],\n",
       "       [3192.5046],\n",
       "       [3202.3362],\n",
       "       [3209.957 ],\n",
       "       [3199.549 ],\n",
       "       [3197.428 ],\n",
       "       [3184.0015],\n",
       "       [3197.9993],\n",
       "       [3207.7285],\n",
       "       [3202.796 ],\n",
       "       [3191.6633],\n",
       "       [3180.3137],\n",
       "       [3164.4734],\n",
       "       [3147.9673],\n",
       "       [3151.7725],\n",
       "       [3174.2053],\n",
       "       [3199.726 ],\n",
       "       [3204.6843],\n",
       "       [3185.4414],\n",
       "       [3160.066 ],\n",
       "       [3159.2168],\n",
       "       [3151.8682],\n",
       "       [3153.7554],\n",
       "       [3154.6174],\n",
       "       [3164.5874],\n",
       "       [3160.263 ],\n",
       "       [3164.884 ],\n",
       "       [3171.7783],\n",
       "       [3167.608 ],\n",
       "       [3178.7102],\n",
       "       [3188.9165],\n",
       "       [3204.7734],\n",
       "       [3218.4417],\n",
       "       [3233.7942],\n",
       "       [3235.2817],\n",
       "       [3245.3872],\n",
       "       [3253.815 ],\n",
       "       [3245.489 ],\n",
       "       [3237.8145],\n",
       "       [3243.7288],\n",
       "       [3250.093 ],\n",
       "       [3256.26  ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e35677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_a/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
